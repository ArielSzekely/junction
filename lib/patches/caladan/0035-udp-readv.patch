From 17e5fe34a04ab786b51a49ec1ad220a606160a48 Mon Sep 17 00:00:00 2001
From: Josh Fried <joshuafried@gmail.com>
Date: Wed, 9 Oct 2024 18:29:54 -0400
Subject: [PATCH 35/35] udp readv

---
 inc/runtime/udp.h |  2 ++
 runtime/net/udp.c | 71 +++++++++++++++++++++++++++++++++++++++++++++++
 2 files changed, 73 insertions(+)

diff --git a/inc/runtime/udp.h b/inc/runtime/udp.h
index bde1aba..38eb5b0 100644
--- a/inc/runtime/udp.h
+++ b/inc/runtime/udp.h
@@ -45,6 +45,8 @@ extern ssize_t udp_read_from2(udpconn_t *c, void *buf, size_t len,
 			     struct netaddr *raddr, bool peek, bool nonblocking);
 extern ssize_t udp_write_to2(udpconn_t *c, const void *buf, size_t len,
 			    const struct netaddr *raddr, bool nonblocking);
+extern ssize_t udp_readv_from2(udpconn_t *c, const struct iovec *iov, int iovcnt,
+                      struct netaddr *raddr, bool peek, bool nonblocking);
 
 static inline ssize_t udp_read_from(udpconn_t *c, void *buf, size_t len,
 			     struct netaddr *raddr)
diff --git a/runtime/net/udp.c b/runtime/net/udp.c
index 0926388..dde3737 100644
--- a/runtime/net/udp.c
+++ b/runtime/net/udp.c
@@ -390,6 +390,77 @@ ssize_t udp_read_from2(udpconn_t *c, void *buf, size_t len,
 	return ret;
 }
 
+ssize_t udp_readv_from2(udpconn_t *c, const struct iovec *iov, int iovcnt,
+                      struct netaddr *raddr, bool peek, bool nonblocking)
+{
+	ssize_t ret;
+	struct mbuf *m;
+
+	spin_lock_np(&c->inq_lock);
+	nonblocking |= c->nonblocking;
+
+	/* block until there is an actionable event */
+	while (mbufq_empty(&c->inq) && !c->inq_err && !c->shutdown) {
+		if (nonblocking) {
+			spin_unlock_np(&c->inq_lock);
+			return -EAGAIN;
+		}
+		ret = waitq_wait(&c->inq_wq, &c->inq_lock);
+		if (unlikely(ret)) {
+			spin_unlock_np(&c->inq_lock);
+			return ret;
+		}
+	}
+
+	/* is the socket drained and shutdown? */
+	if (mbufq_empty(&c->inq) && c->shutdown) {
+		spin_unlock_np(&c->inq_lock);
+		return 0;
+	}
+
+	/* propagate error status code if an error was detected */
+	if (c->inq_err) {
+		spin_unlock_np(&c->inq_lock);
+		return -c->inq_err;
+	}
+
+	if (likely(!peek)) {
+		/* pop an mbuf and deliver the payload */
+		m = mbufq_pop_head(&c->inq);
+		if (--c->inq_len == 0 && !c->shutdown)
+			poll_clear(&c->poll_src, POLLIN);
+		spin_unlock_np(&c->inq_lock);
+	} else {
+		m = mbufq_peak_head(&c->inq);
+	}
+
+	ret = 0;
+	for (int i = 0; i < iovcnt; i++) {
+		size_t cpylen = MIN(iov[i].iov_len, mbuf_length(m));
+		memcpy(iov[i].iov_base, mbuf_pull(m, cpylen), cpylen);
+		ret += cpylen;
+		if (!mbuf_length(m))
+			break;
+	}
+
+	if (raddr) {
+		struct ip_hdr *iphdr = mbuf_network_hdr(m, *iphdr);
+		struct udp_hdr *udphdr = mbuf_transport_hdr(m, *udphdr);
+		raddr->ip = ntoh32(iphdr->saddr);
+		raddr->port = ntoh16(udphdr->src_port);
+		if (c->e.match == TRANS_MATCH_5TUPLE) {
+			assert(c->e.raddr.ip == raddr->ip &&
+			       c->e.raddr.port == raddr->port);
+		}
+	}
+
+	if (likely(!peek))
+		mbuf_free(m);
+	else
+		spin_unlock_np(&c->inq_lock);
+	return ret;
+}
+
 static void udp_tx_release_mbuf(struct mbuf *m)
 {
 	udpconn_t *c = (udpconn_t *)m->release_data;
-- 
2.43.0

