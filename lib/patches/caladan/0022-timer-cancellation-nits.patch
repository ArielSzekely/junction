From 2b5ac62a09b0a6a879617ce1719e31b54948ffe1 Mon Sep 17 00:00:00 2001
From: Josh Fried <joshuafried@gmail.com>
Date: Sun, 19 Feb 2023 14:50:21 -0500
Subject: [PATCH 22/22] timer cancellation, nits

---
 inc/runtime/timer.h | 21 ++++++++++++++++++++-
 runtime/sched.c     |  6 +++---
 runtime/timer.c     |  5 ++---
 3 files changed, 25 insertions(+), 7 deletions(-)

diff --git a/inc/runtime/timer.h b/inc/runtime/timer.h
index 7c6ed68..f086f75 100644
--- a/inc/runtime/timer.h
+++ b/inc/runtime/timer.h
@@ -4,6 +4,7 @@
 
 #pragma once
 
+#include <asm/atomic.h>
 #include <base/stddef.h>
 
 typedef void (*timer_fn_t)(unsigned long arg);
@@ -34,12 +35,30 @@ static inline void
 timer_init(struct timer_entry *e, timer_fn_t fn, unsigned long arg)
 {
 	e->armed = false;
+	e->executing = false;
 	e->fn = fn;
 	e->arg = arg;
 }
 
+static inline bool timer_busy(struct timer_entry *e)
+{
+	return load_acquire(&e->armed) || load_acquire(&e->executing);
+}
+
 extern void timer_start(struct timer_entry *e, uint64_t deadline_us);
-extern bool timer_cancel(struct timer_entry *e);
+extern bool __timer_cancel(struct timer_entry *e);
+static inline bool timer_cancel(struct timer_entry *e)
+{
+	if (!load_acquire(&e->armed)) {
+		if (unlikely(load_acquire(&e->executing))) {
+			while (load_acquire(&e->executing))
+				cpu_relax();
+		}
+		return false;
+	}
+
+	return __timer_cancel(e);
+}
 
 
 /*
diff --git a/runtime/sched.c b/runtime/sched.c
index 08414d3..828be86 100644
--- a/runtime/sched.c
+++ b/runtime/sched.c
@@ -334,15 +334,15 @@ static __noreturn __noinline void schedule(void)
 	assert_spin_lock_held(&l->lock);
 	assert(l->parked == false);
 
+	/* detect misuse of preempt disable */
+	BUG_ON((perthread_read(preempt_cnt) & ~PREEMPT_NOT_PENDING) != 1);
+
 	/* unmark busy for the stack of the last uthread */
 	if (likely(perthread_get_stable(__self) != NULL)) {
 		store_release(&perthread_get_stable(__self)->thread_running, false);
 		perthread_get_stable(__self) = NULL;
 	}
 
-	/* detect misuse of preempt disable */
-	BUG_ON((perthread_read(preempt_cnt) & ~PREEMPT_NOT_PENDING) != 1);
-
 	/* update entry stat counters */
 	STAT(RESCHEDULES)++;
 	start_tsc = rdtsc();
diff --git a/runtime/timer.c b/runtime/timer.c
index f5849eb..507b598 100644
--- a/runtime/timer.c
+++ b/runtime/timer.c
@@ -171,7 +171,7 @@ void timer_start(struct timer_entry *e, uint64_t deadline_us)
  * Returns true if the timer was successfully cancelled, otherwise it has
  * already fired or was never armed.
  */
-bool timer_cancel(struct timer_entry *e)
+bool __timer_cancel(struct timer_entry *e)
 {
 	struct kthread *k = e->localk;
 	int last;
@@ -181,7 +181,6 @@ bool timer_cancel(struct timer_entry *e)
 	if (!e->armed) {
 		spin_unlock_np(&k->timer_lock);
 		if (unlikely(load_acquire(&e->executing))) {
-			/* wait until the timer callback finishes */
 			while (load_acquire(&e->executing))
 				cpu_relax();
 		}
@@ -268,8 +267,8 @@ static void timer_softirq_one(struct kthread *k)
 			sift_down(k->timers, 0, i);
 		}
 		update_q_ptrs(k);
-		e->armed = false;
 		e->executing = true;
+		store_release(&e->armed, false);
 		spin_unlock(&k->timer_lock);
 
 		/* execute the timer handler */
-- 
2.34.1

