From 9c14516c0116bd2863d2332bf18fedc981aa9f9e Mon Sep 17 00:00:00 2001
From: Josh Fried <joshuafried@gmail.com>
Date: Sun, 15 Jan 2023 16:14:12 -0500
Subject: [PATCH 4/4] glibc: directly allocate/free stacks from junction

---
 nptl/allocatestack.c | 50 +++++++++++++++++++++++++++++++-------------
 nptl/descr.h         |  2 ++
 nptl/nptl-stack.c    | 16 ++++++++++++++
 3 files changed, 54 insertions(+), 14 deletions(-)

diff --git a/nptl/allocatestack.c b/nptl/allocatestack.c
index 219854f2cb..26df1f3e6e 100644
--- a/nptl/allocatestack.c
+++ b/nptl/allocatestack.c
@@ -215,6 +215,7 @@ allocate_stack (const struct pthread_attr *attr, struct pthread **pdp,
 		void **stack, size_t *stacksize)
 {
   struct pthread *pd;
+  bool uses_junction_stack = false;
   size_t size;
   size_t pagesize_m1 = __getpagesize () - 1;
   size_t tls_static_size_for_stack = __nptl_tls_static_size_for_stack ();
@@ -223,10 +224,25 @@ allocate_stack (const struct pthread_attr *attr, struct pthread **pdp,
   assert (powerof2 (pagesize_m1 + 1));
   assert (TCB_ALIGNMENT >= STACK_ALIGN);
 
+  int attr_flags = attr->flags;
+  size_t attr_guardsize = attr->guardsize;
+  void *attr_stackaddr = attr->stackaddr;
+  size_t attr_stacksize = attr->stacksize;
+
+  if (__glibc_likely(!(attr_flags & ATTR_FLAG_STACKADDR))) {
+    extern int allocate_stack2(void **stack_bottom_out, size_t *stack_size_out, size_t *guard_size_out);
+    typeof(allocate_stack2) **fn = (void *)0x202000UL;
+    int ret = (*fn)(&attr_stackaddr, &attr_stacksize, &attr_guardsize);
+    if (__glibc_likely(ret == 0)) {
+      attr_flags |= ATTR_FLAG_STACKADDR;
+      uses_junction_stack = true;
+    }
+  }
+
   /* Get the stack size from the attribute if it is set.  Otherwise we
      use the default we determined at start time.  */
-  if (attr->stacksize != 0)
-    size = attr->stacksize;
+  if (attr_stacksize != 0)
+    size = attr_stacksize;
   else
     {
       lll_lock (__default_pthread_attr_lock, LLL_PRIVATE);
@@ -235,21 +251,21 @@ allocate_stack (const struct pthread_attr *attr, struct pthread **pdp,
     }
 
   /* Get memory for the stack.  */
-  if (__glibc_unlikely (attr->flags & ATTR_FLAG_STACKADDR))
+  if (__glibc_likely (attr_flags & ATTR_FLAG_STACKADDR))
     {
       uintptr_t adj;
-      char *stackaddr = (char *) attr->stackaddr;
+      char *stackaddr = (char *) attr_stackaddr;
 
       /* Assume the same layout as the _STACK_GROWS_DOWN case, with struct
 	 pthread at the top of the stack block.  Later we adjust the guard
 	 location and stack address to match the _STACK_GROWS_UP case.  */
       if (_STACK_GROWS_UP)
-	stackaddr += attr->stacksize;
+	stackaddr += attr_stacksize;
 
       /* If the user also specified the size of the stack make sure it
 	 is large enough.  */
-      if (attr->stacksize != 0
-	  && attr->stacksize < (tls_static_size_for_stack
+      if (attr_stacksize != 0
+	  && attr_stacksize < (tls_static_size_for_stack
 				+ MINIMAL_REST_STACK))
 	return EINVAL;
 
@@ -291,6 +307,9 @@ allocate_stack (const struct pthread_attr *attr, struct pthread **pdp,
 	 stack cache nor will the memory (except the TLS memory) be freed.  */
       pd->user_stack = true;
 
+      if (uses_junction_stack)
+        pd->uses_junction_stack = true;
+
       /* This is at least the second thread.  */
       pd->header.multiple_threads = 1;
 
@@ -309,14 +328,17 @@ allocate_stack (const struct pthread_attr *attr, struct pthread **pdp,
 	  return errno;
 	}
 
+      if (!uses_junction_stack) {
+        /* Prepare to modify global data.  */
+        lll_lock (GL (dl_stack_cache_lock), LLL_PRIVATE);
 
-      /* Prepare to modify global data.  */
-      lll_lock (GL (dl_stack_cache_lock), LLL_PRIVATE);
+        /* And add to the list of stacks in use.  */
+        list_add (&pd->list, &GL (dl_stack_user));
 
-      /* And add to the list of stacks in use.  */
-      list_add (&pd->list, &GL (dl_stack_user));
+        lll_unlock (GL (dl_stack_cache_lock), LLL_PRIVATE);
+      }
+      pd->reported_guardsize = attr_guardsize;
 
-      lll_unlock (GL (dl_stack_cache_lock), LLL_PRIVATE);
     }
   else
     {
@@ -340,11 +362,11 @@ allocate_stack (const struct pthread_attr *attr, struct pthread **pdp,
 	 before POSIX 2008 the guardsize was specified to be one page
 	 by default which is observable via pthread_attr_getguardsize
 	 and pthread_getattr_np.  */
-      guardsize = (attr->guardsize + pagesize_m1) & ~pagesize_m1;
+      guardsize = (attr_guardsize + pagesize_m1) & ~pagesize_m1;
       reported_guardsize = guardsize;
       if (guardsize > 0 && guardsize < ARCH_MIN_GUARD_SIZE)
 	guardsize = ARCH_MIN_GUARD_SIZE;
-      if (guardsize < attr->guardsize || size + guardsize < guardsize)
+      if (guardsize < attr_guardsize || size + guardsize < guardsize)
 	/* Arithmetic overflow.  */
 	return EINVAL;
       size += guardsize;
diff --git a/nptl/descr.h b/nptl/descr.h
index 5cacb286f3..3e4cad408c 100644
--- a/nptl/descr.h
+++ b/nptl/descr.h
@@ -173,6 +173,8 @@ struct pthread
      therefore stack) used' flag.  */
   pid_t tid;
 
+  int uses_junction_stack;
+
   /* List of robust mutexes the thread is holding.  */
 #if __PTHREAD_MUTEX_HAVE_PREV
   void *robust_prev;
diff --git a/nptl/nptl-stack.c b/nptl/nptl-stack.c
index 20ce78eddb..bd4bf24431 100644
--- a/nptl/nptl-stack.c
+++ b/nptl/nptl-stack.c
@@ -109,6 +109,22 @@ queue_stack (struct pthread *stack)
 void
 __nptl_deallocate_stack (struct pthread *pd)
 {
+  if (pd->uses_junction_stack) {
+    struct pthread *self = THREAD_SELF;
+    _dl_deallocate_tls (TLS_TPADJ (pd), false);
+
+    if (pd != self) {
+      extern void free_stack(void *stack_top);
+      typeof(free_stack) **fn = (void *)0x202008UL;
+      (*fn)(pd->stackblock);
+    } else {
+      extern void free_stack_on_exit(void *stack_top);
+      typeof(free_stack_on_exit) **fn = (void *)0x202010UL;
+      (*fn)(pd->stackblock);
+    }
+    return;
+  }
+
   lll_lock (GL (dl_stack_cache_lock), LLL_PRIVATE);
 
   /* Remove the thread from the list of threads with user defined
-- 
2.34.1

